{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Training MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5nzoD2LwGrL5vZX2egjUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prikshit-2000/Tensorflow/blob/main/Custom_Training_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe1aonkmHDng"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense , Flatten , Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.ticker as mticker"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNdcU6MrHDMP"
      },
      "source": [
        "train_data = tfds.load('fashion_mnist',split = 'train')\n",
        "test_data = tfds.load('fashion_mnist' , split = 'test')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cQaIdNUHOJs"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser/pants\", \"Pullover shirt\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yq8fHD2HRaH"
      },
      "source": [
        "def format_image(data):\n",
        "  image = data['image']\n",
        "  image  = tf.reshape(image,[-1])\n",
        "  image = tf.cast(image,'float32')\n",
        "  image = image/255.0\n",
        "\n",
        "  return image,data['label']\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkahnp90Hlul"
      },
      "source": [
        "train_data = train_data.map(format_image)\n",
        "test_data = test_data.map(format_image)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi2wQrxPHr_r"
      },
      "source": [
        "batch_size = 64\n",
        "train = train_data.shuffle(buffer_size = 1024).batch(batch_size)\n",
        "test = test_data.batch(batch_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2gvhR4PHdbQ"
      },
      "source": [
        "def base_model():\n",
        "  inputs = Input(shape = (784,) , name = 'clothing')\n",
        "  x = Dense(64 , activation = 'relu' , name = 'dense_1')(inputs)\n",
        "  x = Dense(64 , activation = 'relu' , name = 'dense_2')(x)\n",
        "  x  = Dense(10, activation = 'softmax' , name = 'predictions')(x)\n",
        "  model = Model(inputs = inputs , outputs = x)\n",
        "  return model\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW2NSjxwIIMN"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibMllXBEIQos"
      },
      "source": [
        "train_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t97NzljJQeZ"
      },
      "source": [
        "def apply_gradient(optimizer, model , x , y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    loss = loss_object(y,logits)\n",
        "\n",
        "  grads = tape.gradient(loss , model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
        "\n",
        "  return logits,loss\n",
        "\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ2dhCT5JiNf"
      },
      "source": [
        "def train_data_for_one_epoch():\n",
        "  losses = []\n",
        "\n",
        "  for step,(batch_x,batch_y) in enumerate(train):\n",
        "    logits,loss = apply_gradient(optimizer , model , batch_x , batch_y)\n",
        "    losses.append(loss)\n",
        "\n",
        "    train_metric(batch_y,logits)\n",
        "  return losses"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4mTJCLGdM8Z"
      },
      "source": [
        "def perform_validation():\n",
        "  losses = []\n",
        "\n",
        "  for batch_x,batch_y in (test):\n",
        "    logits = model(batch_x)\n",
        "    val_loss = loss_object(batch_y,logits,)\n",
        "    losses.append(val_loss)\n",
        "    val_metric(batch_y,logits)\n",
        "  return losses\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACnsYh2veAf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a900d47c-b922-49f2-8328-9e715c7eb607"
      },
      "source": [
        "model = base_model()\n",
        "\n",
        "epochs = 20\n",
        "val_loss , train_loss = [] , []\n",
        "for i in range(epochs):\n",
        "  losses_train = train_data_for_one_epoch()\n",
        "  train_acc = train_metric.result()\n",
        "\n",
        "  losses_val = perform_validation()\n",
        "  val_acc = val_metric.result()\n",
        "\n",
        "\n",
        "  losses_train_mean = np.mean(losses_train)\n",
        "  losses_val_mean = np.mean(losses_val)\n",
        "\n",
        "  train_loss.append(losses_train_mean)\n",
        "  val_loss.append(losses_val_mean)\n",
        "  print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' % (i, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc)))\n",
        "  train_metric.reset_states()\n",
        "  val_metric.reset_states()  "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 0: Train loss: 0.4842  Validation Loss: 0.4227, Train Accuracy: 0.8261, Validation Accuracy 0.8459\n",
            "\n",
            " Epoch 1: Train loss: 0.3668  Validation Loss: 0.3905, Train Accuracy: 0.8667, Validation Accuracy 0.8603\n",
            "\n",
            " Epoch 2: Train loss: 0.3342  Validation Loss: 0.3667, Train Accuracy: 0.8780, Validation Accuracy 0.8714\n",
            "\n",
            " Epoch 3: Train loss: 0.3156  Validation Loss: 0.3620, Train Accuracy: 0.8829, Validation Accuracy 0.8704\n",
            "\n",
            " Epoch 4: Train loss: 0.2990  Validation Loss: 0.3631, Train Accuracy: 0.8905, Validation Accuracy 0.8706\n",
            "\n",
            " Epoch 5: Train loss: 0.2870  Validation Loss: 0.3425, Train Accuracy: 0.8958, Validation Accuracy 0.8783\n",
            "\n",
            " Epoch 6: Train loss: 0.2784  Validation Loss: 0.3426, Train Accuracy: 0.8982, Validation Accuracy 0.8777\n",
            "\n",
            " Epoch 7: Train loss: 0.2695  Validation Loss: 0.3500, Train Accuracy: 0.9000, Validation Accuracy 0.8756\n",
            "\n",
            " Epoch 8: Train loss: 0.2614  Validation Loss: 0.3501, Train Accuracy: 0.9038, Validation Accuracy 0.8755\n",
            "\n",
            " Epoch 9: Train loss: 0.2552  Validation Loss: 0.3444, Train Accuracy: 0.9050, Validation Accuracy 0.8826\n",
            "\n",
            " Epoch 10: Train loss: 0.2478  Validation Loss: 0.3426, Train Accuracy: 0.9082, Validation Accuracy 0.8802\n",
            "\n",
            " Epoch 11: Train loss: 0.2424  Validation Loss: 0.3494, Train Accuracy: 0.9095, Validation Accuracy 0.8805\n",
            "\n",
            " Epoch 12: Train loss: 0.2365  Validation Loss: 0.3377, Train Accuracy: 0.9114, Validation Accuracy 0.8833\n",
            "\n",
            " Epoch 13: Train loss: 0.2319  Validation Loss: 0.3393, Train Accuracy: 0.9143, Validation Accuracy 0.8849\n",
            "\n",
            " Epoch 14: Train loss: 0.2264  Validation Loss: 0.3427, Train Accuracy: 0.9142, Validation Accuracy 0.8870\n",
            "\n",
            " Epoch 15: Train loss: 0.2231  Validation Loss: 0.3570, Train Accuracy: 0.9160, Validation Accuracy 0.8827\n",
            "\n",
            " Epoch 16: Train loss: 0.2170  Validation Loss: 0.3547, Train Accuracy: 0.9195, Validation Accuracy 0.8830\n",
            "\n",
            " Epoch 17: Train loss: 0.2132  Validation Loss: 0.3570, Train Accuracy: 0.9197, Validation Accuracy 0.8831\n",
            "\n",
            " Epoch 18: Train loss: 0.2089  Validation Loss: 0.3579, Train Accuracy: 0.9210, Validation Accuracy 0.8816\n",
            "\n",
            " Epoch 19: Train loss: 0.2055  Validation Loss: 0.3714, Train Accuracy: 0.9227, Validation Accuracy 0.8801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mw7ecBwKECa"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}